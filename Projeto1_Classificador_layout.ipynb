{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Rodrigo Carvalho Monteiro de Barros\n",
    "(sem dupla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import operator\n",
    "import functools\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo HBO max.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'HBO max.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.)\n",
    "\n",
    "__O produto alvo do trabalho foi o recem lançado serviço de streaming \"HBO max\". O objetivo é, a partir de tweets que mencionem o produto, obter informações sobre a opinião e aceitação (ou não) dos usuarios (ou possiveis usuarios) desse tipo de serviço, a fim de descobrir se o produto fez sucesso desde seu lançamento e se conseguirá lugar no crescente mercado de serviços de streeming.__ \n",
    "\n",
    "Foram considerados relevantes comentarios de opinião sobre o serviço, sejam eles positivos ou negativos, e principalmente comparativos com outros serviços do ramo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente foram criadas funções e listas que serão usadas ao longo do codigo. Aqui encontram-se as funções para limpara caracteres especiais e para separar emojis de texto. Também está definido aqui o que foi considerado como *stopwprd* para efeitos desse trabalho.\n",
    "\n",
    "__Stopword:__ Uma stopword (ou no português:'palavra vazia'), é para a computação o termo usado para denominar uma palavra que é removida antes ou após o processamento de um texto. Não existe uma lista oficial de *stopwords*, pois elas devem se adequar ao contexto em que se faz necessario separa-las, e por isso há necessidade de explicita-las abaixo. No caso desse projeto, foram separadas palavras que nao agregam relevância para a classificação das mensagens, como conectivos, artigos, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de limpeza que troca alguns sinais básicos por espaços \n",
    "def cleanup(text):\n",
    "    #Retira as sequências de controle\n",
    "    text = text.replace(\"\\\\n\", '').replace(\"\\n\\n\", '').replace(\"\\n\", '')\n",
    "    #Parte \"muito simples\" retirado do material de aula.\n",
    "    punctuation = '[!-..:?;_—•|/\\‘’“”@#$%&]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    #substitui as palavras \"hbo\", \"max\", \"rt\" e \"https\" que nao interverem na relevancia da mensagem.\n",
    "    text_subbed = text_subbed.replace(\"hbo\",'').replace(\"max\",'').replace(\"rt\", '').replace(\"https\", '')\n",
    "    return text_subbed\n",
    "\n",
    "#Função que aucilia na limpesa do material analizado, separando emojis de outros caracteres.        \n",
    "def separa_emoji(lista):\n",
    "    lista_split_emoji = emoji.get_emoji_regexp().split(lista)\n",
    "    lista_split_whitespace = [substr.split() for substr in lista_split_emoji]\n",
    "    lista_split = functools.reduce(operator.concat, lista_split_whitespace)\n",
    "    return lista_split\n",
    "\n",
    "#Lista de palavras que nos interessam e serão usadas para comparação mais tarde.    \n",
    "importantes = ['netflix','amazon','hulu','disney','youtube','sling','fubo','crackle','crunchyroll'\\\n",
    "               ,'vrv','thestreamingwars','streamingwars','streaming' ]    \n",
    "\n",
    "#lista de 'stopwords' para serem removidas depois:\n",
    "stopwords = ['the', 'i', 'to', 'on', 'it', 'its', 'is', 'and', 'of', 'a', 'for', 'this', 'in', 'that', 'so', 'an', 'or'\\\n",
    "            , 'with', 'has', 'had', 'at', 'if', 'as', 'by', 'have', 'are', 'get', 'can', 'cant', 'was', 'than', 'but'\\\n",
    "            , 'im', 'be', 'you', 'my', 'me', 'ive', 'been', 'we', 'our']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando o dataframe em dois, de acordo com a relevancia feita na coragem.\n",
    "train_relevantes = train.loc[train.Relevancia == 1]\n",
    "train_irrelevantes = train.loc[train.Relevancia== 0]\n",
    "\n",
    "#O codigo não le o dataframe inteiro a menos que ele esteja esposto, se não ele le apenas o \"resumo\" que aparece no 'print'.\n",
    "#Estas funções fazem com que o conteúdo por inteiro seja exposto. \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#================ Relevantes ===============================================================================\n",
    "#\"lista_relevante\" é uma enore lista com todos os tweeets relevantes, ja aplicado o cleanup.\n",
    "lista_relevante = cleanup(str(train_relevantes.Treinamento))\n",
    "#agora aplica-se a função que separa caracteres colados em emojis\n",
    "lista_relevante = separa_emoji(lista_relevante.lower())\n",
    "#\"serie_relevante\" é um novo dataframe com todas as palavras reparadas.\n",
    "serie_relevante = pd.Series(lista_relevante)\n",
    "#criando uma tabela com a contagem da quantidade de cada palavra. Depois, retira as stopwords.\n",
    "tabela_relevantes = serie_relevante.value_counts()\n",
    "tabela_relevantes = tabela_relevantes.drop(labels=stopwords)\n",
    "\n",
    "#================ Irrelevantes =============================================================================\n",
    "#Agora o mesmo para as irrelevantes.\n",
    "lista_irrelevante = cleanup(str(train_irrelevantes.Treinamento))\n",
    "lista_irrelevante = separa_emoji(lista_irrelevante.lower())\n",
    "serie_irrelevante = pd.Series(lista_irrelevante)\n",
    "tabela_irrelevantes = serie_irrelevante.value_counts()\n",
    "tabela_irrelevantes = tabela_irrelevantes.drop(labels=stopwords)\n",
    "\n",
    "#================ Conjunto completo ========================================================================\n",
    "#agora o mesmo para o conjunto completo\n",
    "lista_completa = cleanup(str(train.Treinamento))\n",
    "lista_completa = separa_emoji(lista_completa.lower())\n",
    "serie_completa = pd.Series(lista_completa)\n",
    "tabela_completa = serie_completa.value_counts()\n",
    "tabela_completa = tabela_completa.drop(labels=stopwords)\n",
    "\n",
    "#==========================================================================================================\n",
    "#Calculando as probabilidades da palavra ser relevante ou irrelevante dado o conjunto completo.\n",
    "P_rel = len(serie_relevante)/len(serie_completa)\n",
    "P_irrel = 1 - P_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa funçao calcula a probabilidade de uma dada palavra estar no grupo relevante e de estar no grupo irrelevante.\n",
    "def calcula_probabilidades(palavra):\n",
    "\n",
    "    if palavra in tabela_relevantes:\n",
    "        R = tabela_relevantes[palavra]\n",
    "    else:\n",
    "        R = 0\n",
    "        \n",
    "    if palavra in tabela_irrelevantes:\n",
    "        I = tabela_irrelevantes[palavra]\n",
    "    else:\n",
    "        I = 0           \n",
    "            \n",
    "    Rel_p = (R + 1) / (len(lista_relevante) + 1*len(train))\n",
    "    Irrel_p = (I + 1) / (len(lista_irrelevante) + 1*len(train))\n",
    "    return [Rel_p, Irrel_p] #  Rel_p = P(palavra|Relevantes)  ||  Irrel_p = P(palavra|Irrelevantes)\n",
    "\n",
    "#Essa funçao usa a anterior para calcular a probabilidade de uma dada frase, por palavra, estar no grupo relevante e\n",
    "#de estar no grupo irrelevante. Então as compara e retorna a relevância da frase.\n",
    "def compara_probabilidades(frase):\n",
    "    frase = separa_emoji(cleanup(str(frase)).lower())\n",
    "    Rel = 1\n",
    "    Irrel = 1    \n",
    "    for palavra in frase:\n",
    "        Rel *= calcula_probabilidades(palavra)[0]\n",
    "        Irrel *= calcula_probabilidades(palavra)[1]\n",
    "    if Rel >= Irrel:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando as funções\n",
    "lista_teste = []\n",
    "for e in test['Teste']:\n",
    "    lista_teste.append(compara_probabilidades(e))\n",
    "test[\"classificador\"] = lista_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros positivos:  46.6 %\n",
      "Falsos positivos:  25.0 %\n",
      "Verdadeiros negativos:  25.0 %\n",
      "Falsos negativos:  3.4 %\n",
      "----------------------------------------\n",
      "Acertos:  71.6 %\n",
      "Erros:  28.4 %\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#\"comparados\" é uma tabela comparativa dos valores de relevancia atribuidos manualmente e pelo classificador\n",
    "comparados = pd.crosstab(test['Relevancia'],test['classificador'], normalize='index')\n",
    "\n",
    "#separando os valores da tabela \n",
    "pos_true = comparados[1][1]/2\n",
    "pos_false = comparados[1][0]/2\n",
    "neg_true = comparados[0][0]/2\n",
    "neg_false =comparados[0][1]/2\n",
    "\n",
    "print(\"Verdadeiros positivos: \", round(pos_true*100,2), \"%\")\n",
    "print(\"Falsos positivos: \", round(pos_false*100, 2), \"%\")\n",
    "print(\"Verdadeiros negativos: \", round(neg_true*100,2), \"%\")\n",
    "print(\"Falsos negativos: \", round(neg_false*100, 2), \"%\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"Acertos: \", round((pos_true+neg_true)*100,2), \"%\")\n",
    "print(\"Erros: \", round((pos_false+neg_false)*100,2), \"%\")\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros positivos:  46.6 %\n",
      "Falsos positivos:  25.0 %\n",
      "Verdadeiros negativos:  25.0 %\n",
      "Falsos negativos:  3.4 %\n",
      "----------------------------------------------------------------------\n",
      "Classificados como Relevantes (código):  71.6 %\n",
      "Classificados como Irelevantes (código):  28.4 %\n",
      "\n",
      "Classificados como Relevantes (Manualmente):  41.7 %\n",
      "Classificados como Irelevantes (Manualmente):  58.3 %\n",
      "----------------------------------------------------------------------\n",
      "Acertos:  71.6 %    (verdadeiros positivos e verdadeiros negativos)\n",
      "Erros:  28.4 %    (falsos positivos e falsos negativos)\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#criando tabelas separadas com os valores de relevância\n",
    "test_relevantes = test.loc[test.Relevancia == 1]\n",
    "test_irrelevantes = test.loc[test.Relevancia== 0]\n",
    "#================================================================================\n",
    "\n",
    "print(\"Verdadeiros positivos: \", round(pos_true*100,2), \"%\")\n",
    "print(\"Falsos positivos: \", round(pos_false*100, 2), \"%\")\n",
    "print(\"Verdadeiros negativos: \", round(neg_true*100,2), \"%\")\n",
    "print(\"Falsos negativos: \", round(neg_false*100, 2), \"%\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"Classificados como Relevantes (código): \", round((pos_true+pos_false)*100,2), \"%\")\n",
    "print(\"Classificados como Irelevantes (código): \", round((neg_true+neg_false)*100,2), \"%\")\n",
    "print(\"\")\n",
    "print(\"Classificados como Relevantes (Manualmente): \", round((len(test_relevantes)/len(test))*100,2), \"%\")\n",
    "print(\"Classificados como Irelevantes (Manualmente): \", round((len(test_irrelevantes)/len(test))*100,2), \"%\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"Acertos: \", round((pos_true+neg_true)*100,2), \"%    (verdadeiros positivos e verdadeiros negativos)\")\n",
    "print(\"Erros: \", round((pos_false+neg_false)*100,2), \"%    (falsos positivos e falsos negativos)\")\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Analise de sentimento:__ <br>\n",
    "A partir dos valores de acertos e erros impressos acima, pode-se concluir que o classificador tem resultados satisfatórios para o que foi proposto, e ajuda bastante a seleção de tweets condizentes com o critério de seleção, de forma que certamente seu uso torna a busca significantemente mais favorável do que sua ausencia. A taxa de falsos negativos foi baixíssima, sendo a taxa de falsos positivos o maior problema do atual código. Uma causa provável do limite de desempenho alcançado pelo classificador é o critério ultilizado para a classificação manual, que pode ter sido vago demais para se obter uma base mais concreta para o classificador. Uma possível solução para esse problema seria obter mais tweets para a base de treinamento do codígo, afim de tornar esse \"critério vago\" em algo mais claro em termos de quantidade de palavras.\n",
    "***\n",
    "__Classificação avançada__ <br>\n",
    "A fim de melhorar a separação do classificador, foi criada uma segunda função que separa os tweets em quatro categorias: \"irrelevantes\", \"Relevantes\", \"Muito relevantes\" e \"Destaque\". As novas categorias funcionam da seguinte maneira: <br><br>\n",
    "*Muito relevantes:* Quando a probabilidade de o tweet ser relevante é significantemente mais provável do que de ser irrelevante.<br><br>\n",
    "*Destaque:* Quando o tweet apresenta o nome de algum concorrente ou tag que diretamente referencie a comparação entre serviços de Streaming ele ganha destaque imediato nessa categoria, uma vez que o objetivo do projeto é saber sobre o espaço do produto no mercado de trabalho, assumindo que sempre é interessante saber quando o produto for mencionado junto com os concorrentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Resultado da Classificação Avançada:\n",
      "----------------------------------------\n",
      "Irrelevantes:  27.53 %\n",
      "Relevantes:  38.06 %\n",
      "Muito Relevantes:  21.05 %\n",
      "Destaques:  13.36 %\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Essa funçao usa a mesma função \"calcula_probabilidades\"de antes, para calcular a probabilidade de uma dada frase,\n",
    "# por palavra, estar no grupo relevante e de estar no grupo irrelevante. Então as compara e retorna a relevância da frase\n",
    "# de acordo com os novos criterios descritos acima.\n",
    "def compara_probabilidades_avançado(frase):\n",
    "    frase = separa_emoji(cleanup(str(frase)).lower())\n",
    "    Rel = 1\n",
    "    Irrel = 1    \n",
    "    for palavra in frase:\n",
    "        Rel *= calcula_probabilidades(palavra)[0]\n",
    "        Irrel *= calcula_probabilidades(palavra)[1]\n",
    "        if palavra in importantes:\n",
    "            return 3    \n",
    "    if Rel/Irrel > 1000:\n",
    "        return 2\n",
    "    elif Rel >= Irrel:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "lista_teste_avançado = []\n",
    "for e in test['Teste']:\n",
    "    lista_teste_avançado.append(compara_probabilidades_avançado(e))\n",
    "test[\"classificador_avançado\"] = lista_teste_avançado\n",
    "\n",
    "Classificador_avançado = test.classificador_avançado.value_counts(normalize=True, sort=False)\n",
    "\n",
    "print(\"-\"*40)\n",
    "print(\"Resultado da Classificação Avançada:\")\n",
    "print(\"-\"*40)\n",
    "Irrelevantes_A = Classificador_avançado[0]\n",
    "Relevantes_A = Classificador_avançado[1]\n",
    "muito_relevantes_A = Classificador_avançado[2]\n",
    "detaque_A = Classificador_avançado[3]\n",
    "\n",
    "print(\"Irrelevantes: \", round(Irrelevantes_A*100,2), \"%\")\n",
    "print(\"Relevantes: \", round(Relevantes_A*100,2), \"%\")\n",
    "print(\"Muito Relevantes: \", round(muito_relevantes_A*100,2), \"%\")\n",
    "print(\"Destaques: \", round(detaque_A*100,2), \"%\")\n",
    "print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Analise de sentimento do Classificador avançado:__ <br>\n",
    "O Classificador avançado conseguiu valores satisfatórios para as categorias avançadas, e a proporção de tweets relevantes para muito relevates está equilibrada. A separação dos destaques se provou eficiente também. <br>\n",
    "É importante resaltar que o mesmo erro de quase 30% do antigo classificador vale ainda para o 'Classificador avançado', assim como as possíveis causas desse erro e as possíveis soluções.\n",
    "\n",
    "***\n",
    "__Plano de expanção:__ <br>\n",
    "Para melhorar ainda mais o código, além de uma maior base de treinamento ou um critério mais claro, pode-se pensar em analisar frases com dupla-negativa ou sarcasmo, funções que o atual código não realiza. Seria necessario analisar a montagem das frases e quantidade de uso de expressões negativas por tweet no primeiro caso, e analisar o significado de emojis e sua coerencia com o conteúdo escrito pode ajudar a identificar ironia e sarcasmo.\n",
    "\n",
    "***\n",
    "__Uso do próprio classificador para gerar amostras de treinamento:__ <br>\n",
    "Não pode-se usar tweets analisados pelo classificador como novas amostras de treinamento para aperfeiçoa-lo. Com uma imprecisão de quase 30%, a nova amostra alimentaria o classificador com erros desde sua origem, de forma que esses se propagariam e levariam a um erro cada vez maior e mais distante do critério de classificalção inicial.\n",
    "\n",
    "***\n",
    "__Uso do classificador Naive Bayes em outros contextos:__<br>\n",
    "Um classificador do tipo Naive Bayes pode ser muito útil em diversos contextos. Por exemplo agora no final do ano um classificador desses poderia ser usado para medir o quanto cada candidato a prefeitura de um estado está sendo comentado nas redes sociais. Um código desses seria mais complexo, tendo que levar em consideração a inclusão digital do público de cada candidato, ou então poderia ser usado para descobrir exatamente esse parâmetro. Esse classificador não poderia ser usado para previsões de voto, mas pode ser um parametro interessante para pensar estratégias de propaganda digital e entender quem tem mais espaço nesse meio, uma vez que nas eleições precidenciais de 2018 muitos disseram que o meio digital foi mais importante meio de propaganda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "Referencia para função de separação dos Emojis:\\\n",
    "https://stackoverflow.com/questions/49921720/how-to-split-emoji-from-each-other-python\n",
    "\n",
    "Referencia para a funçao de limpesa de sequências de controle (e outros):\\\n",
    "https://pt.stackoverflow.com/questions/289388/como-remover-n-de-um-string-em-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
